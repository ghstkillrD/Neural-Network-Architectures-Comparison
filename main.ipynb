{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1277fd80",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Flatten' object has no attribute 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 81\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_loss, test_acc, history\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Split dataset into training and testing sets\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Train and evaluate basic Simple Neural Network\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m simple_nn_basic \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_simple_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m test_loss_basic_nn, test_acc_basic_nn, history_basic_nn \u001b[38;5;241m=\u001b[39m train_and_evaluate(simple_nn_basic, X_train, X_test, y_train, y_test)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Train and evaluate basic Convolutional Neural Network\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m, in \u001b[0;36mcreate_simple_nn\u001b[1;34m(input_shape, num_classes)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_simple_nn\u001b[39m(input_shape, num_classes):\n\u001b[0;32m     26\u001b[0m     model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     27\u001b[0m         layers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[0;32m     28\u001b[0m         layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     29\u001b[0m         layers\u001b[38;5;241m.\u001b[39mDense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     30\u001b[0m     ])\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_shape\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Flatten' object has no attribute 'output_shape'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Load PyTorch tensor files\n",
    "train_data = torch.load('train_data.pt')\n",
    "test_data = torch.load('test_data.pt')\n",
    "train_labels = torch.load('train_labels.pt')\n",
    "test_labels = torch.load('test_labels.pt')\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays\n",
    "X_train = train_data.numpy()\n",
    "X_test = test_data.numpy()\n",
    "y_train = train_labels.numpy()\n",
    "y_test = test_labels.numpy()\n",
    "\n",
    "# Calculate the number of classes\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Define Simple Neural Network architecture (Basic)\n",
    "def create_simple_nn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=input_shape),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define Convolutional Neural Network architecture (Basic)\n",
    "def create_conv_nn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define Improved Simple Neural Network architecture\n",
    "def create_improved_simple_nn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=input_shape),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define Improved Convolutional Neural Network architecture\n",
    "def create_improved_conv_nn(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate models\n",
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test, batch_size=32, epochs=10):\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    return test_loss, test_acc, history\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate basic Simple Neural Network\n",
    "simple_nn_basic = create_simple_nn(input_shape=X_train.shape[1:], num_classes=num_classes)\n",
    "test_loss_basic_nn, test_acc_basic_nn, history_basic_nn = train_and_evaluate(simple_nn_basic, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Train and evaluate basic Convolutional Neural Network\n",
    "conv_nn_basic = create_conv_nn(input_shape=X_train.shape[1:], num_classes=num_classes)\n",
    "test_loss_basic_conv_nn, test_acc_basic_conv_nn, history_basic_conv_nn = train_and_evaluate(conv_nn_basic, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Train and evaluate improved Simple Neural Network\n",
    "improved_simple_nn = create_improved_simple_nn(input_shape=X_train.shape[1:], num_classes=num_classes)\n",
    "test_loss_improved_simple_nn, test_acc_improved_simple_nn, history_improved_simple_nn = train_and_evaluate(improved_simple_nn, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Train and evaluate improved Convolutional Neural Network\n",
    "improved_conv_nn = create_improved_conv_nn(input_shape=X_train.shape[1:], num_classes=num_classes)\n",
    "test_loss_improved_conv_nn, test_acc_improved_conv_nn, history_improved_conv_nn = train_and_evaluate(improved_conv_nn, X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "# Test different learning rates\n",
    "learning_rates = [0.00000001, 10]\n",
    "for lr in learning_rates:\n",
    "    conv_nn_optimized = create_improved_conv_nn(input_shape=X_train.shape[1:], num_classes=num_classes)\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    conv_nn_optimized.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history_optimized = conv_nn_optimized.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882ad67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
